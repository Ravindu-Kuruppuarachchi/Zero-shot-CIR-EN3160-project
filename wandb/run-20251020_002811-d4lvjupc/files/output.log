
Running evaluation for dataset: fiq
load checkpoint from D:/Documents 2.0/5th semester/computer vision/Vision Project/model_base_retrieval_coco.pth
missing keys:
[]
Only the text encoder will be fine-tuned
Target pad with target_ratio = 1.25 preprocess pipeline is used
Laion 'train' dataset initialized with 2000 triplets.
Looking for images in: D:/Documents 2.0/5th semester/computer vision/Vision Project/laion_cir_template/laion_cir_template
FashionIQ val - ['dress'] dataset in relative mode initialized
FashionIQ val - ['dress'] dataset in classic mode initialized
FashionIQ val - ['toptee'] dataset in relative mode initialized
FashionIQ val - ['toptee'] dataset in classic mode initialized
FashionIQ val - ['shirt'] dataset in relative mode initialized
FashionIQ val - ['shirt'] dataset in classic mode initialized
Precomputing FashionIQ validation index features...



100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [08:29<00:00, 101.81s/it]


100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:22<00:00, 22.17s/it]

 25%|█████████████████████████████████████████████████████████████████████████                                                                                                                                                                                                                           | 1/4 [01:06<03:19, 66.64s/it]
Finished precomputing features.
--- Starting FashionIQ Evaluation-Only Mode ---

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:08<00:00, 17.22s/it]
Error loading model checkpoint: Error(s) in loading state_dict for TransAgg:
	Missing key(s) in state_dict: "pretrained_model.temp", "pretrained_model.image_queue", "pretrained_model.text_queue", "pretrained_model.idx_queue", "pretrained_model.ptr_queue", "pretrained_model.visual_encoder.cls_token", "pretrained_model.visual_encoder.pos_embed", "pretrained_model.visual_encoder.patch_embed.proj.weight", "pretrained_model.visual_encoder.patch_embed.proj.bias", "pretrained_model.visual_encoder.blocks.0.norm1.weight", "pretrained_model.visual_encoder.blocks.0.norm1.bias", "pretrained_model.visual_encoder.blocks.0.attn.qkv.weight", "pretrained_model.visual_encoder.blocks.0.attn.qkv.bias", "pretrained_model.visual_encoder.blocks.0.attn.proj.weight", "pretrained_model.visual_encoder.blocks.0.attn.proj.bias", "pretrained_model.visual_encoder.blocks.0.norm2.weight", "pretrained_model.visual_encoder.blocks.0.norm2.bias", "pretrained_model.visual_encoder.blocks.0.mlp.fc1.weight", "pretrained_model.visual_encoder.blocks.0.mlp.fc1.bias", "pretrained_model.visual_encoder.blocks.0.mlp.fc2.weight", "pretrained_model.visual_encoder.blocks.0.mlp.fc2.bias", "pretrained_model.visual_encoder.blocks.1.norm1.weight", "pretrained_model.visual_encoder.blocks.1.norm1.bias", "pretrained_model.visual_encoder.blocks.1.attn.qkv.weight", "pretrained_model.visual_encoder.blocks.1.attn.qkv.bias", "pretrained_model.visual_encoder.blocks.1.attn.proj.weight", "pretrained_model.visual_encoder.blocks.1.attn.proj.bias", "pretrained_model.visual_encoder.blocks.1.norm2.weight", "pretrained_model.visual_encoder.blocks.1.norm2.bias", "pretrained_model.visual_encoder.blocks.1.mlp.fc1.weight", "pretrained_model.visual_encoder.blocks.1.mlp.fc1.bias", "pretrained_model.visual_encoder.blocks.1.mlp.fc2.weight", "pretrained_model.visual_encoder.blocks.1.mlp.fc2.bias", "pretrained_model.visual_encoder.blocks.2.norm1.weight", "pretrained_model.visual_encoder.blocks.2.norm1.bias", "pretrained_model.visual_encoder.blocks.2.attn.qkv.weight", "pretrained_model.visual_encoder.blocks.2.attn.qkv.bias", "pretrained_model.visual_encoder.blocks.2.attn.proj.weight", "pretrained_model.visual_encoder.blocks.2.attn.proj.bias", "pretrained_model.visual_encoder.blocks.2.norm2.weight", "pretrained_model.visual_encoder.blocks.2.norm2.bias", "pretrained_model.visual_encoder.blocks.2.mlp.fc1.weight", "pretrained_model.visual_encoder.blocks.2.mlp.fc1.bias", "pretrained_model.visual_encoder.blocks.2.mlp.fc2.weight", "pretrained_model.visual_encoder.blocks.2.mlp.fc2.bias", "pretrained_model.visual_encoder.blocks.3.norm1.weight", "pretrained_model.visual_encoder.blocks.3.norm1.bias", "pretrained_model.visual_encoder.blocks.3.attn.qkv.weight", "pretrained_model.visual_encoder.blocks.3.attn.qkv.bias", "pretrained_model.visual_encoder.blocks.3.attn.proj.weight", "pretrained_model.visual_encoder.blocks.3.attn.proj.bias", "pretrained_model.visual_encoder.blocks.3.norm2.weight", "pretrained_model.visual_encoder.blocks.3.norm2.bias", "pretrained_model.visual_encoder.blocks.3.mlp.fc1.weight", "pretrained_model.visual_encoder.blocks.3.mlp.fc1.bias", "pretrained_model.visual_encoder.blocks.3.mlp.fc2.weight", "pretrained_model.visual_encoder.blocks.3.mlp.fc2.bias", "pretrained_model.visual_encoder.blocks.4.norm1.weight", "pretrained_model.visual_encoder.blocks.4.norm1.bias", "pretrained_model.visual_encoder.blocks.4.attn.qkv.weight", "pretrained_model.visual_encoder.blocks.4.attn.qkv.bias", "pretrained_model.visual_encoder.blocks.4.attn.proj.weight", "pretrained_model.visual_encoder.blocks.4.attn.proj.bias", "pretrained_model.visual_encoder.blocks.4.norm2.weight", "pretrained_model.visual_encoder.blocks.4.norm2.bias", "pretrained_model.visual_encoder.blocks.4.mlp.fc1.weight", "pretrained_model.visual_encoder.blocks.4.mlp.fc1.bias", "pretrained_model.visual_encoder.blocks.4.mlp.fc2.weight", "pretrained_model.visual_encoder.blocks.4.mlp.fc2.bias", "pretrained_model.visual_encoder.blocks.5.norm1.weight", "pretrained_model.visual_encoder.blocks.5.norm1.bias", "pretrained_model.visual_encoder.blocks.5.attn.qkv.weight", "pretrained_model.visual_encoder.blocks.5.attn.qkv.bias", "pretrained_model.visual_encoder.blocks.5.attn.proj.weight", "pretrained_model.visual_encoder.blocks.5.attn.proj.bias", "pretrained_model.visual_encoder.blocks.5.norm2.weight", "pretrained_model.visual_encoder.blocks.5.norm2.bias", "pretrained_model.visual_encoder.blocks.5.mlp.fc1.weight", "pretrained_model.visual_encoder.blocks.5.mlp.fc1.bias", "pretrained_model.visual_encoder.blocks.5.mlp.fc2.weight", "pretrained_model.visual_encoder.blocks.5.mlp.fc2.bias", "pretrained_model.visual_encoder.blocks.6.norm1.weight", "pretrained_model.visual_encoder.blocks.6.norm1.bias", "pretrained_model.visual_encoder.blocks.6.attn.qkv.weight", "pretrained_model.visual_encoder.blocks.6.attn.qkv.bias", "pretrained_model.visual_encoder.blocks.6.attn.proj.weight", "pretrained_model.visual_encoder.blocks.6.attn.proj.bias", "pretrained_model.visual_encoder.blocks.6.norm2.weight", "pretrained_model.visual_encoder.blocks.6.norm2.bias", "pretrained_model.visual_encoder.blocks.6.mlp.fc1.weight", "pretrained_model.visual_encoder.blocks.6.mlp.fc1.bias", "pretrained_model.visual_encoder.blocks.6.mlp.fc2.weight", "pretrained_model.visual_encoder.blocks.6.mlp.fc2.bias", "pretrained_model.visual_encoder.blocks.7.norm1.weight", "pretrained_model.visual_encoder.blocks.7.norm1.bias", "pretrained_model.visual_encoder.blocks.7.attn.qkv.weight", "pretrained_model.visual_encoder.blocks.7.attn.qkv.bias", "pretrained_model.visual_encoder.blocks.7.attn.proj.weight", "pretrained_model.visual_encoder.blocks.7.attn.proj.bias", "pretrained_model.visual_encoder.blocks.7.norm2.weight", "pretrained_model.visual_encoder.blocks.7.norm2.bias", "pretrained_model.visual_encoder.blocks.7.mlp.fc1.weight", "pretrained_model.visual_encoder.blocks.7.mlp.fc1.bias", "pretrained_model.visual_encoder.blocks.7.mlp.fc2.weight", "pretrained_model.visual_encoder.blocks.7.mlp.fc2.bias", "pretrained_model.visual_encoder.blocks.8.norm1.weight", "pretrained_model.visual_encoder.blocks.8.norm1.bias", "pretrained_model.visual_encoder.blocks.8.attn.qkv.weight", "pretrained_model.visual_encoder.blocks.8.attn.qkv.bias", "pretrained_model.visual_encoder.blocks.8.attn.proj.weight", "pretrained_model.visual_encoder.blocks.8.attn.proj.bias", "pretrained_model.visual_encoder.blocks.8.norm2.weight", "pretrained_model.visual_encoder.blocks.8.norm2.bias", "pretrained_model.visual_encoder.blocks.8.mlp.fc1.weight", "pretrained_model.visual_encoder.blocks.8.mlp.fc1.bias", "pretrained_model.visual_encoder.blocks.8.mlp.fc2.weight", "pretrained_model.visual_encoder.blocks.8.mlp.fc2.bias", "pretrained_model.visual_encoder.blocks.9.norm1.weight", "pretrained_model.visual_encoder.blocks.9.norm1.bias", "pretrained_model.visual_encoder.blocks.9.attn.qkv.weight", "pretrained_model.visual_encoder.blocks.9.attn.qkv.bias", "pretrained_model.visual_encoder.blocks.9.attn.proj.weight", "pretrained_model.visual_encoder.blocks.9.attn.proj.bias", "pretrained_model.visual_encoder.blocks.9.norm2.weight", "pretrained_model.visual_encoder.blocks.9.norm2.bias", "pretrained_model.visual_encoder.blocks.9.mlp.fc1.weight", "pretrained_model.visual_encoder.blocks.9.mlp.fc1.bias", "pretrained_model.visual_encoder.blocks.9.mlp.fc2.weight", "pretrained_model.visual_encoder.blocks.9.mlp.fc2.bias", "pretrained_model.visual_encoder.blocks.10.norm1.weight", "pretrained_model.visual_encoder.blocks.10.norm1.bias", "pretrained_model.visual_encoder.blocks.10.attn.qkv.weight", "pretrained_model.visual_encoder.blocks.10.attn.qkv.bias", "pretrained_model.visual_encoder.blocks.10.attn.proj.weight", "pretrained_model.visual_encoder.blocks.10.attn.proj.bias", "pretrained_model.visual_encoder.blocks.10.norm2.weight", "pretrained_model.visual_encoder.blocks.10.norm2.bias", "pretrained_model.visual_encoder.blocks.10.mlp.fc1.weight", "pretrained_model.visual_encoder.blocks.10.mlp.fc1.bias", "pretrained_model.visual_encoder.blocks.10.mlp.fc2.weight", "pretrained_model.visual_encoder.blocks.10.mlp.fc2.bias", "pretrained_model.visual_encoder.blocks.11.norm1.weight", "pretrained_model.visual_encoder.blocks.11.norm1.bias", "pretrained_model.visual_encoder.blocks.11.attn.qkv.weight", "pretrained_model.visual_encoder.blocks.11.attn.qkv.bias", "pretrained_model.visual_encoder.blocks.11.attn.proj.weight", "pretrained_model.visual_encoder.blocks.11.attn.proj.bias", "pretrained_model.visual_encoder.blocks.11.norm2.weight", "pretrained_model.visual_encoder.blocks.11.norm2.bias", "pretrained_model.visual_encoder.blocks.11.mlp.fc1.weight", "pretrained_model.visual_encoder.blocks.11.mlp.fc1.bias", "pretrained_model.visual_encoder.blocks.11.mlp.fc2.weight", "pretrained_model.visual_encoder.blocks.11.mlp.fc2.bias", "pretrained_model.visual_encoder.norm.weight", "pretrained_model.visual_encoder.norm.bias", "pretrained_model.text_encoder.embeddings.position_ids", "pretrained_model.text_encoder.embeddings.word_embeddings.weight", "pretrained_model.text_encoder.embeddings.position_embeddings.weight", "pretrained_model.text_encoder.embeddings.LayerNorm.weight", "pretrained_model.text_encoder.embeddings.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.0.attention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.0.attention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.0.attention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.0.attention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.0.attention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.0.attention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.0.attention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.0.attention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.0.crossattention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.0.crossattention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.0.crossattention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.0.crossattention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.0.crossattention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.0.crossattention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.0.crossattention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.0.crossattention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.0.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.0.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.0.intermediate.dense.weight", "pretrained_model.text_encoder.encoder.layer.0.intermediate.dense.bias", "pretrained_model.text_encoder.encoder.layer.0.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.0.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.0.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.0.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.1.attention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.1.attention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.1.attention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.1.attention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.1.attention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.1.attention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.1.attention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.1.attention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.1.crossattention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.1.crossattention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.1.crossattention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.1.crossattention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.1.crossattention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.1.crossattention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.1.crossattention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.1.crossattention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.1.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.1.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.1.intermediate.dense.weight", "pretrained_model.text_encoder.encoder.layer.1.intermediate.dense.bias", "pretrained_model.text_encoder.encoder.layer.1.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.1.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.1.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.1.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.2.attention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.2.attention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.2.attention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.2.attention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.2.attention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.2.attention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.2.attention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.2.attention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.2.crossattention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.2.crossattention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.2.crossattention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.2.crossattention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.2.crossattention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.2.crossattention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.2.crossattention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.2.crossattention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.2.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.2.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.2.intermediate.dense.weight", "pretrained_model.text_encoder.encoder.layer.2.intermediate.dense.bias", "pretrained_model.text_encoder.encoder.layer.2.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.2.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.2.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.2.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.3.attention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.3.attention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.3.attention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.3.attention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.3.attention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.3.attention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.3.attention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.3.attention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.3.crossattention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.3.crossattention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.3.crossattention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.3.crossattention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.3.crossattention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.3.crossattention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.3.crossattention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.3.crossattention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.3.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.3.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.3.intermediate.dense.weight", "pretrained_model.text_encoder.encoder.layer.3.intermediate.dense.bias", "pretrained_model.text_encoder.encoder.layer.3.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.3.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.3.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.3.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.4.attention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.4.attention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.4.attention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.4.attention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.4.attention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.4.attention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.4.attention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.4.attention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.4.crossattention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.4.crossattention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.4.crossattention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.4.crossattention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.4.crossattention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.4.crossattention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.4.crossattention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.4.crossattention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.4.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.4.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.4.intermediate.dense.weight", "pretrained_model.text_encoder.encoder.layer.4.intermediate.dense.bias", "pretrained_model.text_encoder.encoder.layer.4.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.4.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.4.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.4.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.5.attention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.5.attention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.5.attention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.5.attention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.5.attention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.5.attention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.5.attention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.5.attention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.5.crossattention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.5.crossattention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.5.crossattention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.5.crossattention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.5.crossattention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.5.crossattention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.5.crossattention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.5.crossattention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.5.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.5.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.5.intermediate.dense.weight", "pretrained_model.text_encoder.encoder.layer.5.intermediate.dense.bias", "pretrained_model.text_encoder.encoder.layer.5.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.5.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.5.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.5.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.6.attention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.6.attention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.6.attention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.6.attention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.6.attention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.6.attention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.6.attention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.6.attention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.6.crossattention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.6.crossattention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.6.crossattention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.6.crossattention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.6.crossattention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.6.crossattention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.6.crossattention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.6.crossattention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.6.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.6.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.6.intermediate.dense.weight", "pretrained_model.text_encoder.encoder.layer.6.intermediate.dense.bias", "pretrained_model.text_encoder.encoder.layer.6.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.6.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.6.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.6.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.7.attention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.7.attention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.7.attention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.7.attention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.7.attention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.7.attention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.7.attention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.7.attention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.7.crossattention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.7.crossattention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.7.crossattention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.7.crossattention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.7.crossattention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.7.crossattention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.7.crossattention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.7.crossattention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.7.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.7.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.7.intermediate.dense.weight", "pretrained_model.text_encoder.encoder.layer.7.intermediate.dense.bias", "pretrained_model.text_encoder.encoder.layer.7.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.7.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.7.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.7.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.8.attention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.8.attention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.8.attention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.8.attention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.8.attention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.8.attention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.8.attention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.8.attention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.8.crossattention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.8.crossattention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.8.crossattention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.8.crossattention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.8.crossattention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.8.crossattention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.8.crossattention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.8.crossattention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.8.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.8.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.8.intermediate.dense.weight", "pretrained_model.text_encoder.encoder.layer.8.intermediate.dense.bias", "pretrained_model.text_encoder.encoder.layer.8.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.8.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.8.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.8.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.9.attention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.9.attention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.9.attention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.9.attention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.9.attention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.9.attention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.9.attention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.9.attention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.9.crossattention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.9.crossattention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.9.crossattention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.9.crossattention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.9.crossattention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.9.crossattention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.9.crossattention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.9.crossattention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.9.intermediate.dense.weight", "pretrained_model.text_encoder.encoder.layer.9.intermediate.dense.bias", "pretrained_model.text_encoder.encoder.layer.9.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.9.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.9.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.9.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.10.attention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.10.attention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.10.attention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.10.attention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.10.attention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.10.attention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.10.attention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.10.attention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.10.crossattention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.10.crossattention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.10.crossattention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.10.crossattention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.10.crossattention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.10.crossattention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.10.crossattention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.10.crossattention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.10.intermediate.dense.weight", "pretrained_model.text_encoder.encoder.layer.10.intermediate.dense.bias", "pretrained_model.text_encoder.encoder.layer.10.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.10.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.10.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.10.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.11.attention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.11.attention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.11.attention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.11.attention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.11.attention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.11.attention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.11.attention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.11.attention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.11.crossattention.self.query.weight", "pretrained_model.text_encoder.encoder.layer.11.crossattention.self.query.bias", "pretrained_model.text_encoder.encoder.layer.11.crossattention.self.key.weight", "pretrained_model.text_encoder.encoder.layer.11.crossattention.self.key.bias", "pretrained_model.text_encoder.encoder.layer.11.crossattention.self.value.weight", "pretrained_model.text_encoder.encoder.layer.11.crossattention.self.value.bias", "pretrained_model.text_encoder.encoder.layer.11.crossattention.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.11.crossattention.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder.encoder.layer.11.intermediate.dense.weight", "pretrained_model.text_encoder.encoder.layer.11.intermediate.dense.bias", "pretrained_model.text_encoder.encoder.layer.11.output.dense.weight", "pretrained_model.text_encoder.encoder.layer.11.output.dense.bias", "pretrained_model.text_encoder.encoder.layer.11.output.LayerNorm.weight", "pretrained_model.text_encoder.encoder.layer.11.output.LayerNorm.bias", "pretrained_model.vision_proj.weight", "pretrained_model.vision_proj.bias", "pretrained_model.text_proj.weight", "pretrained_model.text_proj.bias", "pretrained_model.itm_head.weight", "pretrained_model.itm_head.bias", "pretrained_model.visual_encoder_m.cls_token", "pretrained_model.visual_encoder_m.pos_embed", "pretrained_model.visual_encoder_m.patch_embed.proj.weight", "pretrained_model.visual_encoder_m.patch_embed.proj.bias", "pretrained_model.visual_encoder_m.blocks.0.norm1.weight", "pretrained_model.visual_encoder_m.blocks.0.norm1.bias", "pretrained_model.visual_encoder_m.blocks.0.attn.qkv.weight", "pretrained_model.visual_encoder_m.blocks.0.attn.qkv.bias", "pretrained_model.visual_encoder_m.blocks.0.attn.proj.weight", "pretrained_model.visual_encoder_m.blocks.0.attn.proj.bias", "pretrained_model.visual_encoder_m.blocks.0.norm2.weight", "pretrained_model.visual_encoder_m.blocks.0.norm2.bias", "pretrained_model.visual_encoder_m.blocks.0.mlp.fc1.weight", "pretrained_model.visual_encoder_m.blocks.0.mlp.fc1.bias", "pretrained_model.visual_encoder_m.blocks.0.mlp.fc2.weight", "pretrained_model.visual_encoder_m.blocks.0.mlp.fc2.bias", "pretrained_model.visual_encoder_m.blocks.1.norm1.weight", "pretrained_model.visual_encoder_m.blocks.1.norm1.bias", "pretrained_model.visual_encoder_m.blocks.1.attn.qkv.weight", "pretrained_model.visual_encoder_m.blocks.1.attn.qkv.bias", "pretrained_model.visual_encoder_m.blocks.1.attn.proj.weight", "pretrained_model.visual_encoder_m.blocks.1.attn.proj.bias", "pretrained_model.visual_encoder_m.blocks.1.norm2.weight", "pretrained_model.visual_encoder_m.blocks.1.norm2.bias", "pretrained_model.visual_encoder_m.blocks.1.mlp.fc1.weight", "pretrained_model.visual_encoder_m.blocks.1.mlp.fc1.bias", "pretrained_model.visual_encoder_m.blocks.1.mlp.fc2.weight", "pretrained_model.visual_encoder_m.blocks.1.mlp.fc2.bias", "pretrained_model.visual_encoder_m.blocks.2.norm1.weight", "pretrained_model.visual_encoder_m.blocks.2.norm1.bias", "pretrained_model.visual_encoder_m.blocks.2.attn.qkv.weight", "pretrained_model.visual_encoder_m.blocks.2.attn.qkv.bias", "pretrained_model.visual_encoder_m.blocks.2.attn.proj.weight", "pretrained_model.visual_encoder_m.blocks.2.attn.proj.bias", "pretrained_model.visual_encoder_m.blocks.2.norm2.weight", "pretrained_model.visual_encoder_m.blocks.2.norm2.bias", "pretrained_model.visual_encoder_m.blocks.2.mlp.fc1.weight", "pretrained_model.visual_encoder_m.blocks.2.mlp.fc1.bias", "pretrained_model.visual_encoder_m.blocks.2.mlp.fc2.weight", "pretrained_model.visual_encoder_m.blocks.2.mlp.fc2.bias", "pretrained_model.visual_encoder_m.blocks.3.norm1.weight", "pretrained_model.visual_encoder_m.blocks.3.norm1.bias", "pretrained_model.visual_encoder_m.blocks.3.attn.qkv.weight", "pretrained_model.visual_encoder_m.blocks.3.attn.qkv.bias", "pretrained_model.visual_encoder_m.blocks.3.attn.proj.weight", "pretrained_model.visual_encoder_m.blocks.3.attn.proj.bias", "pretrained_model.visual_encoder_m.blocks.3.norm2.weight", "pretrained_model.visual_encoder_m.blocks.3.norm2.bias", "pretrained_model.visual_encoder_m.blocks.3.mlp.fc1.weight", "pretrained_model.visual_encoder_m.blocks.3.mlp.fc1.bias", "pretrained_model.visual_encoder_m.blocks.3.mlp.fc2.weight", "pretrained_model.visual_encoder_m.blocks.3.mlp.fc2.bias", "pretrained_model.visual_encoder_m.blocks.4.norm1.weight", "pretrained_model.visual_encoder_m.blocks.4.norm1.bias", "pretrained_model.visual_encoder_m.blocks.4.attn.qkv.weight", "pretrained_model.visual_encoder_m.blocks.4.attn.qkv.bias", "pretrained_model.visual_encoder_m.blocks.4.attn.proj.weight", "pretrained_model.visual_encoder_m.blocks.4.attn.proj.bias", "pretrained_model.visual_encoder_m.blocks.4.norm2.weight", "pretrained_model.visual_encoder_m.blocks.4.norm2.bias", "pretrained_model.visual_encoder_m.blocks.4.mlp.fc1.weight", "pretrained_model.visual_encoder_m.blocks.4.mlp.fc1.bias", "pretrained_model.visual_encoder_m.blocks.4.mlp.fc2.weight", "pretrained_model.visual_encoder_m.blocks.4.mlp.fc2.bias", "pretrained_model.visual_encoder_m.blocks.5.norm1.weight", "pretrained_model.visual_encoder_m.blocks.5.norm1.bias", "pretrained_model.visual_encoder_m.blocks.5.attn.qkv.weight", "pretrained_model.visual_encoder_m.blocks.5.attn.qkv.bias", "pretrained_model.visual_encoder_m.blocks.5.attn.proj.weight", "pretrained_model.visual_encoder_m.blocks.5.attn.proj.bias", "pretrained_model.visual_encoder_m.blocks.5.norm2.weight", "pretrained_model.visual_encoder_m.blocks.5.norm2.bias", "pretrained_model.visual_encoder_m.blocks.5.mlp.fc1.weight", "pretrained_model.visual_encoder_m.blocks.5.mlp.fc1.bias", "pretrained_model.visual_encoder_m.blocks.5.mlp.fc2.weight", "pretrained_model.visual_encoder_m.blocks.5.mlp.fc2.bias", "pretrained_model.visual_encoder_m.blocks.6.norm1.weight", "pretrained_model.visual_encoder_m.blocks.6.norm1.bias", "pretrained_model.visual_encoder_m.blocks.6.attn.qkv.weight", "pretrained_model.visual_encoder_m.blocks.6.attn.qkv.bias", "pretrained_model.visual_encoder_m.blocks.6.attn.proj.weight", "pretrained_model.visual_encoder_m.blocks.6.attn.proj.bias", "pretrained_model.visual_encoder_m.blocks.6.norm2.weight", "pretrained_model.visual_encoder_m.blocks.6.norm2.bias", "pretrained_model.visual_encoder_m.blocks.6.mlp.fc1.weight", "pretrained_model.visual_encoder_m.blocks.6.mlp.fc1.bias", "pretrained_model.visual_encoder_m.blocks.6.mlp.fc2.weight", "pretrained_model.visual_encoder_m.blocks.6.mlp.fc2.bias", "pretrained_model.visual_encoder_m.blocks.7.norm1.weight", "pretrained_model.visual_encoder_m.blocks.7.norm1.bias", "pretrained_model.visual_encoder_m.blocks.7.attn.qkv.weight", "pretrained_model.visual_encoder_m.blocks.7.attn.qkv.bias", "pretrained_model.visual_encoder_m.blocks.7.attn.proj.weight", "pretrained_model.visual_encoder_m.blocks.7.attn.proj.bias", "pretrained_model.visual_encoder_m.blocks.7.norm2.weight", "pretrained_model.visual_encoder_m.blocks.7.norm2.bias", "pretrained_model.visual_encoder_m.blocks.7.mlp.fc1.weight", "pretrained_model.visual_encoder_m.blocks.7.mlp.fc1.bias", "pretrained_model.visual_encoder_m.blocks.7.mlp.fc2.weight", "pretrained_model.visual_encoder_m.blocks.7.mlp.fc2.bias", "pretrained_model.visual_encoder_m.blocks.8.norm1.weight", "pretrained_model.visual_encoder_m.blocks.8.norm1.bias", "pretrained_model.visual_encoder_m.blocks.8.attn.qkv.weight", "pretrained_model.visual_encoder_m.blocks.8.attn.qkv.bias", "pretrained_model.visual_encoder_m.blocks.8.attn.proj.weight", "pretrained_model.visual_encoder_m.blocks.8.attn.proj.bias", "pretrained_model.visual_encoder_m.blocks.8.norm2.weight", "pretrained_model.visual_encoder_m.blocks.8.norm2.bias", "pretrained_model.visual_encoder_m.blocks.8.mlp.fc1.weight", "pretrained_model.visual_encoder_m.blocks.8.mlp.fc1.bias", "pretrained_model.visual_encoder_m.blocks.8.mlp.fc2.weight", "pretrained_model.visual_encoder_m.blocks.8.mlp.fc2.bias", "pretrained_model.visual_encoder_m.blocks.9.norm1.weight", "pretrained_model.visual_encoder_m.blocks.9.norm1.bias", "pretrained_model.visual_encoder_m.blocks.9.attn.qkv.weight", "pretrained_model.visual_encoder_m.blocks.9.attn.qkv.bias", "pretrained_model.visual_encoder_m.blocks.9.attn.proj.weight", "pretrained_model.visual_encoder_m.blocks.9.attn.proj.bias", "pretrained_model.visual_encoder_m.blocks.9.norm2.weight", "pretrained_model.visual_encoder_m.blocks.9.norm2.bias", "pretrained_model.visual_encoder_m.blocks.9.mlp.fc1.weight", "pretrained_model.visual_encoder_m.blocks.9.mlp.fc1.bias", "pretrained_model.visual_encoder_m.blocks.9.mlp.fc2.weight", "pretrained_model.visual_encoder_m.blocks.9.mlp.fc2.bias", "pretrained_model.visual_encoder_m.blocks.10.norm1.weight", "pretrained_model.visual_encoder_m.blocks.10.norm1.bias", "pretrained_model.visual_encoder_m.blocks.10.attn.qkv.weight", "pretrained_model.visual_encoder_m.blocks.10.attn.qkv.bias", "pretrained_model.visual_encoder_m.blocks.10.attn.proj.weight", "pretrained_model.visual_encoder_m.blocks.10.attn.proj.bias", "pretrained_model.visual_encoder_m.blocks.10.norm2.weight", "pretrained_model.visual_encoder_m.blocks.10.norm2.bias", "pretrained_model.visual_encoder_m.blocks.10.mlp.fc1.weight", "pretrained_model.visual_encoder_m.blocks.10.mlp.fc1.bias", "pretrained_model.visual_encoder_m.blocks.10.mlp.fc2.weight", "pretrained_model.visual_encoder_m.blocks.10.mlp.fc2.bias", "pretrained_model.visual_encoder_m.blocks.11.norm1.weight", "pretrained_model.visual_encoder_m.blocks.11.norm1.bias", "pretrained_model.visual_encoder_m.blocks.11.attn.qkv.weight", "pretrained_model.visual_encoder_m.blocks.11.attn.qkv.bias", "pretrained_model.visual_encoder_m.blocks.11.attn.proj.weight", "pretrained_model.visual_encoder_m.blocks.11.attn.proj.bias", "pretrained_model.visual_encoder_m.blocks.11.norm2.weight", "pretrained_model.visual_encoder_m.blocks.11.norm2.bias", "pretrained_model.visual_encoder_m.blocks.11.mlp.fc1.weight", "pretrained_model.visual_encoder_m.blocks.11.mlp.fc1.bias", "pretrained_model.visual_encoder_m.blocks.11.mlp.fc2.weight", "pretrained_model.visual_encoder_m.blocks.11.mlp.fc2.bias", "pretrained_model.visual_encoder_m.norm.weight", "pretrained_model.visual_encoder_m.norm.bias", "pretrained_model.vision_proj_m.weight", "pretrained_model.vision_proj_m.bias", "pretrained_model.text_encoder_m.embeddings.position_ids", "pretrained_model.text_encoder_m.embeddings.word_embeddings.weight", "pretrained_model.text_encoder_m.embeddings.position_embeddings.weight", "pretrained_model.text_encoder_m.embeddings.LayerNorm.weight", "pretrained_model.text_encoder_m.embeddings.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.0.attention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.0.attention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.0.attention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.0.attention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.0.attention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.0.attention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.0.attention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.0.attention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.0.attention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.0.attention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.0.crossattention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.0.crossattention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.0.crossattention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.0.crossattention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.0.crossattention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.0.crossattention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.0.crossattention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.0.crossattention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.0.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.0.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.0.intermediate.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.0.intermediate.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.0.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.0.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.0.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.0.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.1.attention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.1.attention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.1.attention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.1.attention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.1.attention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.1.attention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.1.attention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.1.attention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.1.attention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.1.attention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.1.crossattention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.1.crossattention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.1.crossattention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.1.crossattention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.1.crossattention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.1.crossattention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.1.crossattention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.1.crossattention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.1.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.1.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.1.intermediate.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.1.intermediate.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.1.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.1.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.1.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.1.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.2.attention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.2.attention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.2.attention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.2.attention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.2.attention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.2.attention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.2.attention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.2.attention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.2.attention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.2.attention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.2.crossattention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.2.crossattention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.2.crossattention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.2.crossattention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.2.crossattention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.2.crossattention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.2.crossattention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.2.crossattention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.2.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.2.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.2.intermediate.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.2.intermediate.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.2.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.2.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.2.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.2.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.3.attention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.3.attention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.3.attention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.3.attention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.3.attention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.3.attention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.3.attention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.3.attention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.3.attention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.3.attention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.3.crossattention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.3.crossattention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.3.crossattention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.3.crossattention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.3.crossattention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.3.crossattention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.3.crossattention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.3.crossattention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.3.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.3.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.3.intermediate.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.3.intermediate.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.3.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.3.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.3.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.3.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.4.attention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.4.attention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.4.attention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.4.attention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.4.attention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.4.attention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.4.attention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.4.attention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.4.attention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.4.attention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.4.crossattention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.4.crossattention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.4.crossattention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.4.crossattention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.4.crossattention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.4.crossattention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.4.crossattention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.4.crossattention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.4.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.4.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.4.intermediate.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.4.intermediate.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.4.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.4.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.4.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.4.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.5.attention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.5.attention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.5.attention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.5.attention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.5.attention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.5.attention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.5.attention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.5.attention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.5.attention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.5.attention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.5.crossattention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.5.crossattention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.5.crossattention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.5.crossattention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.5.crossattention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.5.crossattention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.5.crossattention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.5.crossattention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.5.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.5.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.5.intermediate.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.5.intermediate.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.5.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.5.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.5.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.5.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.6.attention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.6.attention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.6.attention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.6.attention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.6.attention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.6.attention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.6.attention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.6.attention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.6.attention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.6.attention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.6.crossattention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.6.crossattention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.6.crossattention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.6.crossattention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.6.crossattention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.6.crossattention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.6.crossattention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.6.crossattention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.6.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.6.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.6.intermediate.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.6.intermediate.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.6.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.6.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.6.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.6.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.7.attention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.7.attention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.7.attention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.7.attention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.7.attention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.7.attention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.7.attention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.7.attention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.7.attention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.7.attention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.7.crossattention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.7.crossattention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.7.crossattention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.7.crossattention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.7.crossattention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.7.crossattention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.7.crossattention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.7.crossattention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.7.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.7.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.7.intermediate.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.7.intermediate.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.7.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.7.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.7.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.7.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.8.attention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.8.attention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.8.attention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.8.attention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.8.attention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.8.attention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.8.attention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.8.attention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.8.attention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.8.attention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.8.crossattention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.8.crossattention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.8.crossattention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.8.crossattention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.8.crossattention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.8.crossattention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.8.crossattention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.8.crossattention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.8.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.8.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.8.intermediate.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.8.intermediate.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.8.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.8.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.8.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.8.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.9.attention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.9.attention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.9.attention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.9.attention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.9.attention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.9.attention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.9.attention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.9.attention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.9.attention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.9.attention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.9.crossattention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.9.crossattention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.9.crossattention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.9.crossattention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.9.crossattention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.9.crossattention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.9.crossattention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.9.crossattention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.9.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.9.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.9.intermediate.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.9.intermediate.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.9.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.9.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.9.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.9.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.10.attention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.10.attention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.10.attention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.10.attention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.10.attention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.10.attention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.10.attention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.10.attention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.10.attention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.10.attention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.10.crossattention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.10.crossattention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.10.crossattention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.10.crossattention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.10.crossattention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.10.crossattention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.10.crossattention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.10.crossattention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.10.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.10.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.10.intermediate.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.10.intermediate.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.10.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.10.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.10.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.10.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.11.attention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.11.attention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.11.attention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.11.attention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.11.attention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.11.attention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.11.attention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.11.attention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.11.attention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.11.attention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.11.crossattention.self.query.weight", "pretrained_model.text_encoder_m.encoder.layer.11.crossattention.self.query.bias", "pretrained_model.text_encoder_m.encoder.layer.11.crossattention.self.key.weight", "pretrained_model.text_encoder_m.encoder.layer.11.crossattention.self.key.bias", "pretrained_model.text_encoder_m.encoder.layer.11.crossattention.self.value.weight", "pretrained_model.text_encoder_m.encoder.layer.11.crossattention.self.value.bias", "pretrained_model.text_encoder_m.encoder.layer.11.crossattention.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.11.crossattention.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.11.crossattention.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.11.crossattention.output.LayerNorm.bias", "pretrained_model.text_encoder_m.encoder.layer.11.intermediate.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.11.intermediate.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.11.output.dense.weight", "pretrained_model.text_encoder_m.encoder.layer.11.output.dense.bias", "pretrained_model.text_encoder_m.encoder.layer.11.output.LayerNorm.weight", "pretrained_model.text_encoder_m.encoder.layer.11.output.LayerNorm.bias", "pretrained_model.text_proj_m.weight", "pretrained_model.text_proj_m.bias".
	Unexpected key(s) in state_dict: "pretrained_model.positional_embedding", "pretrained_model.text_projection", "pretrained_model.logit_scale", "pretrained_model.visual.class_embedding", "pretrained_model.visual.positional_embedding", "pretrained_model.visual.proj", "pretrained_model.visual.conv1.weight", "pretrained_model.visual.ln_pre.weight", "pretrained_model.visual.ln_pre.bias", "pretrained_model.visual.transformer.resblocks.0.attn.in_proj_weight", "pretrained_model.visual.transformer.resblocks.0.attn.in_proj_bias", "pretrained_model.visual.transformer.resblocks.0.attn.out_proj.weight", "pretrained_model.visual.transformer.resblocks.0.attn.out_proj.bias", "pretrained_model.visual.transformer.resblocks.0.ln_1.weight", "pretrained_model.visual.transformer.resblocks.0.ln_1.bias", "pretrained_model.visual.transformer.resblocks.0.mlp.c_fc.weight", "pretrained_model.visual.transformer.resblocks.0.mlp.c_fc.bias", "pretrained_model.visual.transformer.resblocks.0.mlp.c_proj.weight", "pretrained_model.visual.transformer.resblocks.0.mlp.c_proj.bias", "pretrained_model.visual.transformer.resblocks.0.ln_2.weight", "pretrained_model.visual.transformer.resblocks.0.ln_2.bias", "pretrained_model.visual.transformer.resblocks.1.attn.in_proj_weight", "pretrained_model.visual.transformer.resblocks.1.attn.in_proj_bias", "pretrained_model.visual.transformer.resblocks.1.attn.out_proj.weight", "pretrained_model.visual.transformer.resblocks.1.attn.out_proj.bias", "pretrained_model.visual.transformer.resblocks.1.ln_1.weight", "pretrained_model.visual.transformer.resblocks.1.ln_1.bias", "pretrained_model.visual.transformer.resblocks.1.mlp.c_fc.weight", "pretrained_model.visual.transformer.resblocks.1.mlp.c_fc.bias", "pretrained_model.visual.transformer.resblocks.1.mlp.c_proj.weight", "pretrained_model.visual.transformer.resblocks.1.mlp.c_proj.bias", "pretrained_model.visual.transformer.resblocks.1.ln_2.weight", "pretrained_model.visual.transformer.resblocks.1.ln_2.bias", "pretrained_model.visual.transformer.resblocks.2.attn.in_proj_weight", "pretrained_model.visual.transformer.resblocks.2.attn.in_proj_bias", "pretrained_model.visual.transformer.resblocks.2.attn.out_proj.weight", "pretrained_model.visual.transformer.resblocks.2.attn.out_proj.bias", "pretrained_model.visual.transformer.resblocks.2.ln_1.weight", "pretrained_model.visual.transformer.resblocks.2.ln_1.bias", "pretrained_model.visual.transformer.resblocks.2.mlp.c_fc.weight", "pretrained_model.visual.transformer.resblocks.2.mlp.c_fc.bias", "pretrained_model.visual.transformer.resblocks.2.mlp.c_proj.weight", "pretrained_model.visual.transformer.resblocks.2.mlp.c_proj.bias", "pretrained_model.visual.transformer.resblocks.2.ln_2.weight", "pretrained_model.visual.transformer.resblocks.2.ln_2.bias", "pretrained_model.visual.transformer.resblocks.3.attn.in_proj_weight", "pretrained_model.visual.transformer.resblocks.3.attn.in_proj_bias", "pretrained_model.visual.transformer.resblocks.3.attn.out_proj.weight", "pretrained_model.visual.transformer.resblocks.3.attn.out_proj.bias", "pretrained_model.visual.transformer.resblocks.3.ln_1.weight", "pretrained_model.visual.transformer.resblocks.3.ln_1.bias", "pretrained_model.visual.transformer.resblocks.3.mlp.c_fc.weight", "pretrained_model.visual.transformer.resblocks.3.mlp.c_fc.bias", "pretrained_model.visual.transformer.resblocks.3.mlp.c_proj.weight", "pretrained_model.visual.transformer.resblocks.3.mlp.c_proj.bias", "pretrained_model.visual.transformer.resblocks.3.ln_2.weight", "pretrained_model.visual.transformer.resblocks.3.ln_2.bias", "pretrained_model.visual.transformer.resblocks.4.attn.in_proj_weight", "pretrained_model.visual.transformer.resblocks.4.attn.in_proj_bias", "pretrained_model.visual.transformer.resblocks.4.attn.out_proj.weight", "pretrained_model.visual.transformer.resblocks.4.attn.out_proj.bias", "pretrained_model.visual.transformer.resblocks.4.ln_1.weight", "pretrained_model.visual.transformer.resblocks.4.ln_1.bias", "pretrained_model.visual.transformer.resblocks.4.mlp.c_fc.weight", "pretrained_model.visual.transformer.resblocks.4.mlp.c_fc.bias", "pretrained_model.visual.transformer.resblocks.4.mlp.c_proj.weight", "pretrained_model.visual.transformer.resblocks.4.mlp.c_proj.bias", "pretrained_model.visual.transformer.resblocks.4.ln_2.weight", "pretrained_model.visual.transformer.resblocks.4.ln_2.bias", "pretrained_model.visual.transformer.resblocks.5.attn.in_proj_weight", "pretrained_model.visual.transformer.resblocks.5.attn.in_proj_bias", "pretrained_model.visual.transformer.resblocks.5.attn.out_proj.weight", "pretrained_model.visual.transformer.resblocks.5.attn.out_proj.bias", "pretrained_model.visual.transformer.resblocks.5.ln_1.weight", "pretrained_model.visual.transformer.resblocks.5.ln_1.bias", "pretrained_model.visual.transformer.resblocks.5.mlp.c_fc.weight", "pretrained_model.visual.transformer.resblocks.5.mlp.c_fc.bias", "pretrained_model.visual.transformer.resblocks.5.mlp.c_proj.weight", "pretrained_model.visual.transformer.resblocks.5.mlp.c_proj.bias", "pretrained_model.visual.transformer.resblocks.5.ln_2.weight", "pretrained_model.visual.transformer.resblocks.5.ln_2.bias", "pretrained_model.visual.transformer.resblocks.6.attn.in_proj_weight", "pretrained_model.visual.transformer.resblocks.6.attn.in_proj_bias", "pretrained_model.visual.transformer.resblocks.6.attn.out_proj.weight", "pretrained_model.visual.transformer.resblocks.6.attn.out_proj.bias", "pretrained_model.visual.transformer.resblocks.6.ln_1.weight", "pretrained_model.visual.transformer.resblocks.6.ln_1.bias", "pretrained_model.visual.transformer.resblocks.6.mlp.c_fc.weight", "pretrained_model.visual.transformer.resblocks.6.mlp.c_fc.bias", "pretrained_model.visual.transformer.resblocks.6.mlp.c_proj.weight", "pretrained_model.visual.transformer.resblocks.6.mlp.c_proj.bias", "pretrained_model.visual.transformer.resblocks.6.ln_2.weight", "pretrained_model.visual.transformer.resblocks.6.ln_2.bias", "pretrained_model.visual.transformer.resblocks.7.attn.in_proj_weight", "pretrained_model.visual.transformer.resblocks.7.attn.in_proj_bias", "pretrained_model.visual.transformer.resblocks.7.attn.out_proj.weight", "pretrained_model.visual.transformer.resblocks.7.attn.out_proj.bias", "pretrained_model.visual.transformer.resblocks.7.ln_1.weight", "pretrained_model.visual.transformer.resblocks.7.ln_1.bias", "pretrained_model.visual.transformer.resblocks.7.mlp.c_fc.weight", "pretrained_model.visual.transformer.resblocks.7.mlp.c_fc.bias", "pretrained_model.visual.transformer.resblocks.7.mlp.c_proj.weight", "pretrained_model.visual.transformer.resblocks.7.mlp.c_proj.bias", "pretrained_model.visual.transformer.resblocks.7.ln_2.weight", "pretrained_model.visual.transformer.resblocks.7.ln_2.bias", "pretrained_model.visual.transformer.resblocks.8.attn.in_proj_weight", "pretrained_model.visual.transformer.resblocks.8.attn.in_proj_bias", "pretrained_model.visual.transformer.resblocks.8.attn.out_proj.weight", "pretrained_model.visual.transformer.resblocks.8.attn.out_proj.bias", "pretrained_model.visual.transformer.resblocks.8.ln_1.weight", "pretrained_model.visual.transformer.resblocks.8.ln_1.bias", "pretrained_model.visual.transformer.resblocks.8.mlp.c_fc.weight", "pretrained_model.visual.transformer.resblocks.8.mlp.c_fc.bias", "pretrained_model.visual.transformer.resblocks.8.mlp.c_proj.weight", "pretrained_model.visual.transformer.resblocks.8.mlp.c_proj.bias", "pretrained_model.visual.transformer.resblocks.8.ln_2.weight", "pretrained_model.visual.transformer.resblocks.8.ln_2.bias", "pretrained_model.visual.transformer.resblocks.9.attn.in_proj_weight", "pretrained_model.visual.transformer.resblocks.9.attn.in_proj_bias", "pretrained_model.visual.transformer.resblocks.9.attn.out_proj.weight", "pretrained_model.visual.transformer.resblocks.9.attn.out_proj.bias", "pretrained_model.visual.transformer.resblocks.9.ln_1.weight", "pretrained_model.visual.transformer.resblocks.9.ln_1.bias", "pretrained_model.visual.transformer.resblocks.9.mlp.c_fc.weight", "pretrained_model.visual.transformer.resblocks.9.mlp.c_fc.bias", "pretrained_model.visual.transformer.resblocks.9.mlp.c_proj.weight", "pretrained_model.visual.transformer.resblocks.9.mlp.c_proj.bias", "pretrained_model.visual.transformer.resblocks.9.ln_2.weight", "pretrained_model.visual.transformer.resblocks.9.ln_2.bias", "pretrained_model.visual.transformer.resblocks.10.attn.in_proj_weight", "pretrained_model.visual.transformer.resblocks.10.attn.in_proj_bias", "pretrained_model.visual.transformer.resblocks.10.attn.out_proj.weight", "pretrained_model.visual.transformer.resblocks.10.attn.out_proj.bias", "pretrained_model.visual.transformer.resblocks.10.ln_1.weight", "pretrained_model.visual.transformer.resblocks.10.ln_1.bias", "pretrained_model.visual.transformer.resblocks.10.mlp.c_fc.weight", "pretrained_model.visual.transformer.resblocks.10.mlp.c_fc.bias", "pretrained_model.visual.transformer.resblocks.10.mlp.c_proj.weight", "pretrained_model.visual.transformer.resblocks.10.mlp.c_proj.bias", "pretrained_model.visual.transformer.resblocks.10.ln_2.weight", "pretrained_model.visual.transformer.resblocks.10.ln_2.bias", "pretrained_model.visual.transformer.resblocks.11.attn.in_proj_weight", "pretrained_model.visual.transformer.resblocks.11.attn.in_proj_bias", "pretrained_model.visual.transformer.resblocks.11.attn.out_proj.weight", "pretrained_model.visual.transformer.resblocks.11.attn.out_proj.bias", "pretrained_model.visual.transformer.resblocks.11.ln_1.weight", "pretrained_model.visual.transformer.resblocks.11.ln_1.bias", "pretrained_model.visual.transformer.resblocks.11.mlp.c_fc.weight", "pretrained_model.visual.transformer.resblocks.11.mlp.c_fc.bias", "pretrained_model.visual.transformer.resblocks.11.mlp.c_proj.weight", "pretrained_model.visual.transformer.resblocks.11.mlp.c_proj.bias", "pretrained_model.visual.transformer.resblocks.11.ln_2.weight", "pretrained_model.visual.transformer.resblocks.11.ln_2.bias", "pretrained_model.visual.ln_post.weight", "pretrained_model.visual.ln_post.bias", "pretrained_model.transformer.resblocks.0.attn.in_proj_weight", "pretrained_model.transformer.resblocks.0.attn.in_proj_bias", "pretrained_model.transformer.resblocks.0.attn.out_proj.weight", "pretrained_model.transformer.resblocks.0.attn.out_proj.bias", "pretrained_model.transformer.resblocks.0.ln_1.weight", "pretrained_model.transformer.resblocks.0.ln_1.bias", "pretrained_model.transformer.resblocks.0.mlp.c_fc.weight", "pretrained_model.transformer.resblocks.0.mlp.c_fc.bias", "pretrained_model.transformer.resblocks.0.mlp.c_proj.weight", "pretrained_model.transformer.resblocks.0.mlp.c_proj.bias", "pretrained_model.transformer.resblocks.0.ln_2.weight", "pretrained_model.transformer.resblocks.0.ln_2.bias", "pretrained_model.transformer.resblocks.1.attn.in_proj_weight", "pretrained_model.transformer.resblocks.1.attn.in_proj_bias", "pretrained_model.transformer.resblocks.1.attn.out_proj.weight", "pretrained_model.transformer.resblocks.1.attn.out_proj.bias", "pretrained_model.transformer.resblocks.1.ln_1.weight", "pretrained_model.transformer.resblocks.1.ln_1.bias", "pretrained_model.transformer.resblocks.1.mlp.c_fc.weight", "pretrained_model.transformer.resblocks.1.mlp.c_fc.bias", "pretrained_model.transformer.resblocks.1.mlp.c_proj.weight", "pretrained_model.transformer.resblocks.1.mlp.c_proj.bias", "pretrained_model.transformer.resblocks.1.ln_2.weight", "pretrained_model.transformer.resblocks.1.ln_2.bias", "pretrained_model.transformer.resblocks.2.attn.in_proj_weight", "pretrained_model.transformer.resblocks.2.attn.in_proj_bias", "pretrained_model.transformer.resblocks.2.attn.out_proj.weight", "pretrained_model.transformer.resblocks.2.attn.out_proj.bias", "pretrained_model.transformer.resblocks.2.ln_1.weight", "pretrained_model.transformer.resblocks.2.ln_1.bias", "pretrained_model.transformer.resblocks.2.mlp.c_fc.weight", "pretrained_model.transformer.resblocks.2.mlp.c_fc.bias", "pretrained_model.transformer.resblocks.2.mlp.c_proj.weight", "pretrained_model.transformer.resblocks.2.mlp.c_proj.bias", "pretrained_model.transformer.resblocks.2.ln_2.weight", "pretrained_model.transformer.resblocks.2.ln_2.bias", "pretrained_model.transformer.resblocks.3.attn.in_proj_weight", "pretrained_model.transformer.resblocks.3.attn.in_proj_bias", "pretrained_model.transformer.resblocks.3.attn.out_proj.weight", "pretrained_model.transformer.resblocks.3.attn.out_proj.bias", "pretrained_model.transformer.resblocks.3.ln_1.weight", "pretrained_model.transformer.resblocks.3.ln_1.bias", "pretrained_model.transformer.resblocks.3.mlp.c_fc.weight", "pretrained_model.transformer.resblocks.3.mlp.c_fc.bias", "pretrained_model.transformer.resblocks.3.mlp.c_proj.weight", "pretrained_model.transformer.resblocks.3.mlp.c_proj.bias", "pretrained_model.transformer.resblocks.3.ln_2.weight", "pretrained_model.transformer.resblocks.3.ln_2.bias", "pretrained_model.transformer.resblocks.4.attn.in_proj_weight", "pretrained_model.transformer.resblocks.4.attn.in_proj_bias", "pretrained_model.transformer.resblocks.4.attn.out_proj.weight", "pretrained_model.transformer.resblocks.4.attn.out_proj.bias", "pretrained_model.transformer.resblocks.4.ln_1.weight", "pretrained_model.transformer.resblocks.4.ln_1.bias", "pretrained_model.transformer.resblocks.4.mlp.c_fc.weight", "pretrained_model.transformer.resblocks.4.mlp.c_fc.bias", "pretrained_model.transformer.resblocks.4.mlp.c_proj.weight", "pretrained_model.transformer.resblocks.4.mlp.c_proj.bias", "pretrained_model.transformer.resblocks.4.ln_2.weight", "pretrained_model.transformer.resblocks.4.ln_2.bias", "pretrained_model.transformer.resblocks.5.attn.in_proj_weight", "pretrained_model.transformer.resblocks.5.attn.in_proj_bias", "pretrained_model.transformer.resblocks.5.attn.out_proj.weight", "pretrained_model.transformer.resblocks.5.attn.out_proj.bias", "pretrained_model.transformer.resblocks.5.ln_1.weight", "pretrained_model.transformer.resblocks.5.ln_1.bias", "pretrained_model.transformer.resblocks.5.mlp.c_fc.weight", "pretrained_model.transformer.resblocks.5.mlp.c_fc.bias", "pretrained_model.transformer.resblocks.5.mlp.c_proj.weight", "pretrained_model.transformer.resblocks.5.mlp.c_proj.bias", "pretrained_model.transformer.resblocks.5.ln_2.weight", "pretrained_model.transformer.resblocks.5.ln_2.bias", "pretrained_model.transformer.resblocks.6.attn.in_proj_weight", "pretrained_model.transformer.resblocks.6.attn.in_proj_bias", "pretrained_model.transformer.resblocks.6.attn.out_proj.weight", "pretrained_model.transformer.resblocks.6.attn.out_proj.bias", "pretrained_model.transformer.resblocks.6.ln_1.weight", "pretrained_model.transformer.resblocks.6.ln_1.bias", "pretrained_model.transformer.resblocks.6.mlp.c_fc.weight", "pretrained_model.transformer.resblocks.6.mlp.c_fc.bias", "pretrained_model.transformer.resblocks.6.mlp.c_proj.weight", "pretrained_model.transformer.resblocks.6.mlp.c_proj.bias", "pretrained_model.transformer.resblocks.6.ln_2.weight", "pretrained_model.transformer.resblocks.6.ln_2.bias", "pretrained_model.transformer.resblocks.7.attn.in_proj_weight", "pretrained_model.transformer.resblocks.7.attn.in_proj_bias", "pretrained_model.transformer.resblocks.7.attn.out_proj.weight", "pretrained_model.transformer.resblocks.7.attn.out_proj.bias", "pretrained_model.transformer.resblocks.7.ln_1.weight", "pretrained_model.transformer.resblocks.7.ln_1.bias", "pretrained_model.transformer.resblocks.7.mlp.c_fc.weight", "pretrained_model.transformer.resblocks.7.mlp.c_fc.bias", "pretrained_model.transformer.resblocks.7.mlp.c_proj.weight", "pretrained_model.transformer.resblocks.7.mlp.c_proj.bias", "pretrained_model.transformer.resblocks.7.ln_2.weight", "pretrained_model.transformer.resblocks.7.ln_2.bias", "pretrained_model.transformer.resblocks.8.attn.in_proj_weight", "pretrained_model.transformer.resblocks.8.attn.in_proj_bias", "pretrained_model.transformer.resblocks.8.attn.out_proj.weight", "pretrained_model.transformer.resblocks.8.attn.out_proj.bias", "pretrained_model.transformer.resblocks.8.ln_1.weight", "pretrained_model.transformer.resblocks.8.ln_1.bias", "pretrained_model.transformer.resblocks.8.mlp.c_fc.weight", "pretrained_model.transformer.resblocks.8.mlp.c_fc.bias", "pretrained_model.transformer.resblocks.8.mlp.c_proj.weight", "pretrained_model.transformer.resblocks.8.mlp.c_proj.bias", "pretrained_model.transformer.resblocks.8.ln_2.weight", "pretrained_model.transformer.resblocks.8.ln_2.bias", "pretrained_model.transformer.resblocks.9.attn.in_proj_weight", "pretrained_model.transformer.resblocks.9.attn.in_proj_bias", "pretrained_model.transformer.resblocks.9.attn.out_proj.weight", "pretrained_model.transformer.resblocks.9.attn.out_proj.bias", "pretrained_model.transformer.resblocks.9.ln_1.weight", "pretrained_model.transformer.resblocks.9.ln_1.bias", "pretrained_model.transformer.resblocks.9.mlp.c_fc.weight", "pretrained_model.transformer.resblocks.9.mlp.c_fc.bias", "pretrained_model.transformer.resblocks.9.mlp.c_proj.weight", "pretrained_model.transformer.resblocks.9.mlp.c_proj.bias", "pretrained_model.transformer.resblocks.9.ln_2.weight", "pretrained_model.transformer.resblocks.9.ln_2.bias", "pretrained_model.transformer.resblocks.10.attn.in_proj_weight", "pretrained_model.transformer.resblocks.10.attn.in_proj_bias", "pretrained_model.transformer.resblocks.10.attn.out_proj.weight", "pretrained_model.transformer.resblocks.10.attn.out_proj.bias", "pretrained_model.transformer.resblocks.10.ln_1.weight", "pretrained_model.transformer.resblocks.10.ln_1.bias", "pretrained_model.transformer.resblocks.10.mlp.c_fc.weight", "pretrained_model.transformer.resblocks.10.mlp.c_fc.bias", "pretrained_model.transformer.resblocks.10.mlp.c_proj.weight", "pretrained_model.transformer.resblocks.10.mlp.c_proj.bias", "pretrained_model.transformer.resblocks.10.ln_2.weight", "pretrained_model.transformer.resblocks.10.ln_2.bias", "pretrained_model.transformer.resblocks.11.attn.in_proj_weight", "pretrained_model.transformer.resblocks.11.attn.in_proj_bias", "pretrained_model.transformer.resblocks.11.attn.out_proj.weight", "pretrained_model.transformer.resblocks.11.attn.out_proj.bias", "pretrained_model.transformer.resblocks.11.ln_1.weight", "pretrained_model.transformer.resblocks.11.ln_1.bias", "pretrained_model.transformer.resblocks.11.mlp.c_fc.weight", "pretrained_model.transformer.resblocks.11.mlp.c_fc.bias", "pretrained_model.transformer.resblocks.11.mlp.c_proj.weight", "pretrained_model.transformer.resblocks.11.mlp.c_proj.bias", "pretrained_model.transformer.resblocks.11.ln_2.weight", "pretrained_model.transformer.resblocks.11.ln_2.bias", "pretrained_model.token_embedding.weight", "pretrained_model.ln_final.weight", "pretrained_model.ln_final.bias".
	size mismatch for sep_token: copying a param with shape torch.Size([1, 1, 512]) from checkpoint, the shape in current model is torch.Size([1, 1, 256]).
	size mismatch for fusion.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([768, 256]).
	size mismatch for fusion.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for fusion.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([256, 256]).
	size mismatch for fusion.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for fusion.layers.0.linear1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([2048, 256]).
	size mismatch for fusion.layers.0.linear2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([256, 2048]).
	size mismatch for fusion.layers.0.linear2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for fusion.layers.0.norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for fusion.layers.0.norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for fusion.layers.0.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for fusion.layers.0.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for fusion.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([1536, 512]) from checkpoint, the shape in current model is torch.Size([768, 256]).
	size mismatch for fusion.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for fusion.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([256, 256]).
	size mismatch for fusion.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for fusion.layers.1.linear1.weight: copying a param with shape torch.Size([2048, 512]) from checkpoint, the shape in current model is torch.Size([2048, 256]).
	size mismatch for fusion.layers.1.linear2.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([256, 2048]).
	size mismatch for fusion.layers.1.linear2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for fusion.layers.1.norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for fusion.layers.1.norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for fusion.layers.1.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for fusion.layers.1.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for combiner_layer.weight: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for combiner_layer.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for weighted_layer.weight: copying a param with shape torch.Size([3, 512]) from checkpoint, the shape in current model is torch.Size([3, 256]).
	size mismatch for output_layer.weight: copying a param with shape torch.Size([512, 4096]) from checkpoint, the shape in current model is torch.Size([256, 2048]).
	size mismatch for output_layer.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
Please ensure the model_path is correct and the checkpoint matches the model architecture.
Finishing wandb run...